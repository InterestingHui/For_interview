<h1>Redis</h1>
<h3>数据结构</h3>
<details><summary>1.字符串</summary>
<li>redis中的字符串是动态字符串，叫SDS
  <li><b>redis中用到sds的地方</b>：1.字符串对象：除了字符串值对象外，所有的键值对的键都是字符串对象；2.AOF持久化的输入缓冲区是用SDS实现的
  <li><b>SDS的内部结构</b>：<br>(i) buf数组，是一个char类型数组，记录字符串内容。<br>(ii) free属性，int类型，记录buf数组中没有使用的字节的数量。<br>(iii) len属性记录已经使用的字节数量。
  <li><b>SDS和C字符串的区别</b>：
    <br>(i) C字符串需要<b>O（n）</b>获取字符串<b>长度</b>；而SDS只需要<b>O（1）</b>获取字符串<b>长度</b>。
    <br>(ii) C字符串API操作<b>不安全</b>，可能会造成缓冲区溢出；而SDS API操作<b>安全</b>，因为在修改字符串前，会先判断会不会造成字符串缓冲区溢出，如果会的话就会先扩展字符串再修改。
    <br>(iii) SDS的<b>内存重分配</b>次数比C字符串<b>少</b>，这个得益于两个策略——<br>
     &nbsp&nbsp&nbsp&nbsp &nbsp&nbsp(1) 第一个是空间预分配策略，就是API对字符串进行扩展的时候，会分配额外的未使用空间，分配空间的大小取决于SDS的长度：如果SDS的长度小于1MB，那么分配的大小就是同样长度的字符串len属性的长度；如果SDS的长度大于1MB，那么分配的大小就是1MB。
      <br>&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp(2) 第二个是惰性空间释放策略，API在对字符串进行缩短操作的时候，不会释放空闲的未使用空间，而是通过free属性记录未保存的空间长度，以便进行扩展的时候就不用再重分配空间了。（当然API也支持手动释放未保存空间的操作）
    <br>(iv) SDS buf数组保存的<b>数据类型</b>比C字符串<b>更丰富</b>。C字符串只能保存ASCII数据，且不能保存空字符，C字符串遇到的第一个空字符会被视作字符串的结束标志；而SDS不仅能保存ASCII数据，还能保存空字符，以及图片、音频等二进制数据，更加丰富。
    <br>(v) C字符串相较于SDS字符串的唯一好处是，C字符串能使用<b>全部</b>的<b><string.h></b>库中的函数，而SDS只能兼容<b部分</b><string.h>库中的函数。
</details>
    <details><summary>2.链表</summary>
      <li>Redis中的链表是list结构体，里面有指向表头的指针head，和指向表尾的指针tail，类型是listnode类型。然后还有一个记录所含节点数的len属性，是unsigned long类型的，以及三个成员函数：dup复制节点函数、free释放节点函数和match对比节点函数，类型都是void*无类型指针，目的是为了实现链表的多态。
       <li>然后链表的每个节点listnode串联成链表，然后这链表是双端无环，也就是每个节点都有指向前一个节点的prev指针和指向后一个节点的next指针。最后节点存储是值是void*无类型指针，指向存储的值对象，也是为了实现多态。
</details>
<details><summary>3.字典</summary>
  <li>Redis中的字典的实现我自己把它分为三层：最低层是单向链表，也可以说哈希表节点，链表中的每个元素都是一个键值对，每个单向链表就是一个哈希表节点；哈希表节点数组构成哈希表，所以第二层是哈希表；最后由两个哈希表形成一个字典，这才形成了顶层结构字典。
  <li>然后在添加一个键值对的时候，字典通过哈希算法往哈希表中添加节点。期间根据字典维护的负载因子判断是否进行rehash，也就是重新散列。
    <br><b>下面我可以来为刚刚提到的每个概念进行展开讲解包括rehash的方式和使用哈希算法插入键值对的一些关键点</b>:
    <li>首先是最外层的字典，他是一个dict结构体：<br>&nbsp&nbsp&nbsp&nbsp（1）其中type属性是一个指向dictType结构的指针，这个dictType结构封装了各种操作特定类型的键值对的函数。<br>&nbsp&nbsp&nbsp&nbsp（2）dict结构体中还有一个private属性，这个属性保存了需要传给dictType结构中特定类型函数的可选参数。<br>&nbsp&nbsp&nbsp&nbsp（3）另外dict结构体中还含有一个rehashidx属性，记录rehash进行时的当前索引，当没有进行rehash时，它的值是-1<br>&nbsp&nbsp&nbsp&nbsp（4）除此之外就是他的核心结构:ht数组，是一个哈希表数组，且数组大小固定是2，也就是说存储两个哈希表——哈希表[0]和哈希表[1],类型都是dictht结构体，哈希表0用于存储键值对，哈希表1用于rehash。
    <li>然后是第二层——哈希表，也就是刚刚讲到的dictht结构体:
      <br>&nbsp&nbsp&nbsp&nbsp（1）dictht结构体有三个属性:size、sizemask、used，都是unsigned long类型的。其中size记录哈希表的大小，sizemask记录哈希表大小掩码用于计算加入键值对时的索引，sizemask总是等于size-1，used记录哈希表中已有节点的数量。
      <br>&nbsp&nbsp&nbsp&nbsp（2）除此之外就是dictht结构体的核心——table数组，是一个指针数组，每个指针元素都指向一个哈希表节点。
    <li>那么就到了第三层，最低层——哈希表节点，哈希表节点是dictEntry结构体:
      <br>&nbsp&nbsp&nbsp&nbsp（1）dictEntry结构体有两个属性和一个指针，指针就是next指针，指向下一个dictEntry结构体，也就是通过next指针形成了单向链表解决哈希冲突。
      <br>&nbsp&nbsp&nbsp&nbsp（2）dictEntry的两个属性分别是key和v，key就是键值对的键，是void*无类型指针，指向键对象；v就是键值对的值，是一个union集合，可选类型有void*无类型指针、uint64_t和int64_t
      <br><b>以上这就是整个字典结构上的组成</b>。
     <li>之后我再讲一下加入键值对的步骤，加入键值对就三步:
       <br>&nbsp&nbsp&nbsp&nbsp（1）首先是通过调用dictType中的函数计算键的hash值，通过MurmurHash2算法。<br>&nbsp&nbsp&nbsp&nbsp（2）第二步是将sizemask和哈希值进行按位与运算得出要插入的索引值。<br>&nbsp&nbsp&nbsp&nbsp（3）第三步就是通过计算出的索引值，找到当前允许键值对的哈希表的索引，把键值对插入到那个索引的单向链表的表头，就完毕了。<br>
       <b>最后再讲下Rehash</b>
     <li>
       字典在不断扩充或者减少的时候需要进行rehash来调整哈希表结构。字典通过判断负载因子和服务器当前的运行情况来判断是否进行rehash。负载因子=正在使用的哈希表的used属性除以size属性。
       <br>&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp（1）当服务器没有进行BGSAVE命令或者BGREWRITER命令的时候，如果负载因子>=1就执行rehash扩展操作。
       <br>&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp（2）当服务器正在执行BGSAVE命令或者BGREWRITER命令的时候，如果负载因子>=5就执行rehash扩展操作。
       <br>&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp（3）当负载因子<=0.1的时候，程序会自动开始对哈希表进行rehash收缩操作
    <li>rehash的步骤不是一次性的，而是分多次、渐进式地进行，rehash的步骤有四步:
       <br>&nbsp&nbsp&nbsp&nbsp（1）第一步是为哈希表1分配足够的空间：如果执行的是扩展操作，你们哈希表1的空间大小为第一个>=哈希表0的used属性的两倍的一个二次方幂（这里可以举例）;如果执行的收缩操作，你们哈希表1的代销是第一个>=哈希表0的used属性的二次方幂。
       <br>&nbsp&nbsp&nbsp&nbsp（2）第二步是将字典的rehashidx设置为0，表示rehash工作开始，而rehashidx的值就是代表之后转移的时候应该存放的目标索引是多少，从0开始。
       <br>&nbsp&nbsp&nbsp&nbsp（3）第三步就是转移，将哈希表0中的键值对转移到哈希表1中，这个步骤不是一次性的，而是渐进的，每次对字典进行添加、删除、查找、更新的操作都会顺便从哈希表0中转移一个哈希表节点到哈希表1中，转移的时候需要对键值对进行重新散列操作（也就是重新计算索引值和hash值）。所以每次操作都会使rehashidx的值加1。
       <br>&nbsp&nbsp&nbsp&nbsp（4）第四步是当哈希表0的键值对都转移到了哈希表1的时候，字典讲rehashidx的值设置为-1，再将哈希表1设置为哈希表0，哈希表0设置为哈希表1，将新的哈希表1清空为空表，rehash操作完成。
</details>
<details><summary>4.跳跃表</summary>
  <li>跳跃表的核心是一个个串联起来的跳跃表节点，通过跳跃表节点来存储数据，每个跳跃表节点存储指向数据的指针，这里的数据通常是字符串对象。
  <li>跳跃表的特点是有序以及能快速访问查找某个节点。<b>有序</b>是因为每个跳跃表节点都有一个分值属性，跳跃表节点按照分值从小到大排序，当分值相同的时候按字符串对象的字典序从小到大排序；<b>快速访问</b>是因为每个跳跃表节点上都有许多层，层高是一个介于1到32之间的随机数，每个层都有一个指向其它节点的指针和跨度属性，通过这些层的指针不断向后跳跃查找从而实现快速访问，通过跨度计算某个节点的排名。通过跳跃表算法进行建层，它的查找复杂度是平均O(logN)、最坏O(N)的复杂度。
  <li>除此之外，跳跃表结构有同时指向表头节点和表尾节点的指针，而且每个跳跃表节点都有后退指针，所以也支持从后向前遍历，但后退只指向前面一位，不能跳跃。
  <li>另外返回跳跃表的节点个数是O(1)，因为跳跃表有length属性记录跳跃表节点个数；还有一个level属性记录除了表头节点外层数最高的节点的层数。
  <li>不过Redis中使用跳跃表的场景不多：1个是可以用来实现有序集合键；另一个是在集群节点中用做内部数据结构。
</details>    
<details><summary>5.整数集合</summary>
  <li>整数集合是一个可以保存int16、int32、int64等整数值的有序集合，即没有重复元素。
  <li>它的使用场景是 当集合内的元素不多且都是int整型元素时，Redis会采用整数集合作为集合键的底层实现。
  <li>整数集合内有一个contents数组和一个encoding属性，contents数组存储集合内的数据，数据类型有encoding决定，还有length属性能O(1)返回集合的大小
  <li>需要注意的是，整数集合有升级的操作，就是说它的contents数组内的数据的类型不是固定的，当新加入的数的类型比集合内所有的数据类型都要长时，就会进行升级，也就是说会先扩展数组的空间后将所有集合内的数据都提升至新加入的数据的类型，再把新数据加入到集合中。不过升级是不可逆的，即不能降级。升级这个操作是既兼顾了内存同时兼顾灵活性的一种做法。
</details>
<details><summary>压缩列表</summary>
<li>压缩列表是由连续的内存块组成的顺序型数据结构，它的特点是节约内存。
<li>压缩列表的使用场景主要是作为列表键和哈希键的底层实现之一。当列表键中的每个列表项或者哈希键中的每个键和值 要么是小整数，要么是短字符串时，就会采用压缩列表作为列表键或者哈希键的底层实现。
<li>压缩列表的组成有5部分:<br>&nbsp&nbsp&nbsp&nbsp(i)第一部分是zlbytes属性，记录整个压缩列表所占的内存字节数;
  <br>&nbsp&nbsp&nbsp&nbsp(2)第二部分是zltail属性，记录压缩列表表位的节点距离列表的起始地址有多少字节，通过这个偏移量可以O(1)得到表尾节点的地址;<br>&nbsp&nbsp&nbsp&nbsp(3)第三部分是zllen属性，记录压缩列表的节点数;<br>&nbsp&nbsp&nbsp&nbsp(4)第四部分是各个节点，也是压缩列表的主要组成部分;<br>&nbsp&nbsp&nbsp&nbsp(5)第五部分是zlend，用来标记压缩列表的末端
  <li>而压缩列表的单个节点有三个属性，content属性记录节点的值，encoding属性记录节点值的数据类型和长度，还有一个关键属性是<b>previous_entry_length</b>,记录前一个节点的长度，之所以记录这个是为了通过当前节点的地址和该属性计算出前一个节点的地址，从而实现<b>遍历</b>。这个属性的<b>大小</b>不是固定的，要么1字节要么5字节，如果前一个节点的长度小于254字节，那么这个属性就是1字节的，反之就是5字节的。
    所以由于其可变性，就涉及到一个<b>连锁更新</b>的问题，就是如果新加入或者删除某一个节点可能导致下一个节点的previous_entry_length属性的大小改变从而导致下一个节点从小于254字节变成了大于254字节，从而导致再下一个节点大小改变，这就是连锁更新。所以最坏的情况下连锁更新会导致<b>N次空间重分配</b>操作，而每次空间重分配的最坏复杂度是O（N），所以连锁更新的最坏复杂度是O（N²），但实际上发生的几率极低，平均下来压缩列表的操作的复杂度是O(N)的
</details>
    
